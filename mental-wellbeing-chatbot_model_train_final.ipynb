{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676d1012",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-18T15:05:39.723887Z",
     "iopub.status.busy": "2025-01-18T15:05:39.723583Z",
     "iopub.status.idle": "2025-01-18T15:05:40.432354Z",
     "shell.execute_reply": "2025-01-18T15:05:40.431443Z"
    },
    "papermill": {
     "duration": 0.717912,
     "end_time": "2025-01-18T15:05:40.433846",
     "exception": false,
     "start_time": "2025-01-18T15:05:39.715934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/goemotions/README.md\n",
      "/kaggle/input/goemotions/goemotions_model_card.pdf\n",
      "/kaggle/input/goemotions/GoEmotionsFormat.PNG\n",
      "/kaggle/input/goemotions/replace_emotions.py\n",
      "/kaggle/input/goemotions/extract_words.py\n",
      "/kaggle/input/goemotions/calculate_metrics.py\n",
      "/kaggle/input/goemotions/analyze_data.py\n",
      "/kaggle/input/goemotions/tables/emotion_words.csv\n",
      "/kaggle/input/goemotions/data/test.tsv\n",
      "/kaggle/input/goemotions/data/ekman_mapping.json\n",
      "/kaggle/input/goemotions/data/dev.tsv\n",
      "/kaggle/input/goemotions/data/emotions.txt\n",
      "/kaggle/input/goemotions/data/train.tsv\n",
      "/kaggle/input/goemotions/data/ekman_labels.csv\n",
      "/kaggle/input/goemotions/data/sentiment_dict.json\n",
      "/kaggle/input/goemotions/data/sentiment_mapping.json\n",
      "/kaggle/input/goemotions/data/full_dataset/goemotions_2.csv\n",
      "/kaggle/input/goemotions/data/full_dataset/goemotions_1.csv\n",
      "/kaggle/input/goemotions/data/full_dataset/goemotions_3.csv\n",
      "/kaggle/input/goemotions/plots/hierarchical_corr.pdf\n",
      "/kaggle/input/goemotions/plots/number_of_labels.pdf\n",
      "/kaggle/input/goemotions/plots/correlations.pdf\n",
      "/kaggle/input/goemotions/plots/colors.tsv\n",
      "/kaggle/input/goemotions/plots/hierarchical_clustering.pdf\n",
      "/kaggle/input/suicide-watch/Suicide_Detection.csv\n",
      "/kaggle/input/mental-wellbeing-chatbot/scikitlearn/default/2/stacking_emotion_classifier.pkl\n",
      "/kaggle/input/mental-wellbeing-chatbot/scikitlearn/default/2/scaler.pkl\n",
      "/kaggle/input/mental-wellbeing-chatbot/scikitlearn/default/2/RandomForestClassifier_suicide_model.pkl\n",
      "/kaggle/input/mental-wellbeing-chatbot/scikitlearn/default/2/word2vec_model.bin\n",
      "/kaggle/input/mental-wellbeing-chatbot/scikitlearn/default/2/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin\n",
      "/kaggle/input/preprocessed-data/p_suicide_data_input3_90k.csv\n",
      "/kaggle/input/preprocessed-data/p_data_input2_150k.csv\n",
      "/kaggle/input/preprocessed-data/p_data_100k_stop.csv\n",
      "/kaggle/input/preprocessed-data/p_data_input3_211k.csv\n",
      "/kaggle/input/preprocessed-data/p_data_full_stop.csv\n",
      "/kaggle/input/preprocessed-data/p_suicide_data_input.csv\n",
      "/kaggle/input/preprocessed-data/p_suicide_data_30k_stop.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6806f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:05:40.447152Z",
     "iopub.status.busy": "2025-01-18T15:05:40.446819Z",
     "iopub.status.idle": "2025-01-18T15:05:51.735673Z",
     "shell.execute_reply": "2025-01-18T15:05:51.734666Z"
    },
    "papermill": {
     "duration": 11.296799,
     "end_time": "2025-01-18T15:05:51.737096",
     "exception": false,
     "start_time": "2025-01-18T15:05:40.440297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                 Man I love reddit.  eeibobj   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1          TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "\n",
       "    created_utc  rater_id  example_very_unclear  admiration  ...  love  \\\n",
       "0  1.548381e+09         1                 False           0  ...     0   \n",
       "1  1.548084e+09        37                  True           0  ...     0   \n",
       "2  1.546428e+09        37                 False           0  ...     0   \n",
       "3  1.547965e+09        18                 False           0  ...     1   \n",
       "4  1.546669e+09         2                 False           0  ...     0   \n",
       "\n",
       "   nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0            0         0      0            0       0        0        1   \n",
       "1            0         0      0            0       0        0        0   \n",
       "2            0         0      0            0       0        0        0   \n",
       "3            0         0      0            0       0        0        0   \n",
       "4            0         0      0            0       0        0        0   \n",
       "\n",
       "   surprise  neutral  \n",
       "0         0        0  \n",
       "1         0        0  \n",
       "2         0        1  \n",
       "3         0        0  \n",
       "4         0        1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# read dataframes\n",
    "file1 = \"/kaggle/input/goemotions/data/full_dataset/goemotions_1.csv\"\n",
    "file2 = \"/kaggle/input/goemotions/data/full_dataset/goemotions_2.csv\"\n",
    "file3 = \"/kaggle/input/goemotions/data/full_dataset/goemotions_3.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "df3 = pd.read_csv(file3)\n",
    "\n",
    "# combine dataframes\n",
    "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "output_file = \"combined_file.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "combined_df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42b2a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:05:51.751056Z",
     "iopub.status.busy": "2025-01-18T15:05:51.750810Z",
     "iopub.status.idle": "2025-01-18T15:05:56.726758Z",
     "shell.execute_reply": "2025-01-18T15:05:56.725836Z"
    },
    "papermill": {
     "duration": 4.984273,
     "end_time": "2025-01-18T15:05:56.728062",
     "exception": false,
     "start_time": "2025-01-18T15:05:51.743789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when you’ve imported about a gazillion of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  admiration  \\\n",
       "211220                             Everyone likes [NAME].           0   \n",
       "211221  Well when you’ve imported about a gazillion of...           0   \n",
       "211222                                 That looks amazing           1   \n",
       "211223  The FDA has plenty to criticize. But like here...           0   \n",
       "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...           0   \n",
       "\n",
       "        amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
       "211220          0      0          0         0       0          0          0   \n",
       "211221          0      0          0         0       1          0          0   \n",
       "211222          0      0          0         0       0          0          0   \n",
       "211223          0      1          0         0       0          0          0   \n",
       "211224          0      0          0         0       0          0          0   \n",
       "\n",
       "        desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
       "211220       0  ...     1            0         0      0            0       0   \n",
       "211221       0  ...     0            0         0      0            0       0   \n",
       "211222       0  ...     0            0         0      0            0       0   \n",
       "211223       0  ...     0            0         0      0            0       0   \n",
       "211224       0  ...     0            0         0      0            0       0   \n",
       "\n",
       "        remorse  sadness  surprise  neutral  \n",
       "211220        0        0         0        0  \n",
       "211221        0        0         0        0  \n",
       "211222        0        0         0        0  \n",
       "211223        0        0         0        0  \n",
       "211224        0        0         0        0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('combined_file.csv')\n",
    "df_suicide = pd.read_csv('/kaggle/input/suicide-watch/Suicide_Detection.csv')\n",
    "\n",
    "\n",
    "df_mod = df.drop(['id', 'author', 'subreddit', 'link_id', 'parent_id',\n",
    "       'created_utc', 'rater_id', 'example_very_unclear'], axis = 1)\n",
    "\n",
    "df_mod.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1098b76c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:05:56.743247Z",
     "iopub.status.busy": "2025-01-18T15:05:56.742990Z",
     "iopub.status.idle": "2025-01-18T15:05:56.756346Z",
     "shell.execute_reply": "2025-01-18T15:05:56.755671Z"
    },
    "papermill": {
     "duration": 0.02261,
     "end_time": "2025-01-18T15:05:56.757585",
     "exception": false,
     "start_time": "2025-01-18T15:05:56.734975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Hey guys, Hey guys, I'm sad, and I need to fin...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>I'm just so tiredCurrently in college, and doi...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>You Wanna Get More Karma?? No you'll not get it.</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text        class\n",
       "297  Hey guys, Hey guys, I'm sad, and I need to fin...  non-suicide\n",
       "298  I'm just so tiredCurrently in college, and doi...      suicide\n",
       "299   You Wanna Get More Karma?? No you'll not get it.  non-suicide"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_suicide_mod = df_suicide.drop(['Unnamed: 0'], axis = 1)\n",
    "df_suicide_mod = df_suicide_mod.head(300)\n",
    "df_suicide_mod.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d34ef1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:05:56.771614Z",
     "iopub.status.busy": "2025-01-18T15:05:56.771386Z",
     "iopub.status.idle": "2025-01-18T15:26:37.317855Z",
     "shell.execute_reply": "2025-01-18T15:26:37.316818Z"
    },
    "papermill": {
     "duration": 1240.56247,
     "end_time": "2025-01-18T15:26:37.326644",
     "exception": false,
     "start_time": "2025-01-18T15:05:56.764174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>Preprocessed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[that, look, amazing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, FDA, have, plenty, to, criticize, but, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[desktop, link, ^^/r, HelperBot, ^^downvote, ^...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  admiration  \\\n",
       "211222                                 That looks amazing           1   \n",
       "211223  The FDA has plenty to criticize. But like here...           0   \n",
       "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...           0   \n",
       "\n",
       "        amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
       "211222          0      0          0         0       0          0          0   \n",
       "211223          0      1          0         0       0          0          0   \n",
       "211224          0      0          0         0       0          0          0   \n",
       "\n",
       "        desire  ...  nervousness  optimism  pride  realization  relief  \\\n",
       "211222       0  ...            0         0      0            0       0   \n",
       "211223       0  ...            0         0      0            0       0   \n",
       "211224       0  ...            0         0      0            0       0   \n",
       "\n",
       "        remorse  sadness  surprise  neutral  \\\n",
       "211222        0        0         0        0   \n",
       "211223        0        0         0        0   \n",
       "211224        0        0         0        0   \n",
       "\n",
       "                                      Preprocessed_tokens  \n",
       "211222                              [that, look, amazing]  \n",
       "211223  [the, FDA, have, plenty, to, criticize, but, l...  \n",
       "211224  [desktop, link, ^^/r, HelperBot, ^^downvote, ^...  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_tokens(text):\n",
    "   \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if not token.is_punct:\n",
    "            lemmatized_token = token.lemma_\n",
    "            tokens.append(lemmatized_token) \n",
    "    \n",
    "    return tokens\n",
    "\n",
    "df_mod['Preprocessed_tokens'] = df_mod['text'].apply(preprocess_tokens)\n",
    "df_suicide_mod['Preprocessed_tokens'] = df_suicide_mod['text'].apply(preprocess_tokens)\n",
    "\n",
    "df_mod.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a19a332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:26:37.342410Z",
     "iopub.status.busy": "2025-01-18T15:26:37.342115Z",
     "iopub.status.idle": "2025-01-18T15:26:37.469666Z",
     "shell.execute_reply": "2025-01-18T15:26:37.468836Z"
    },
    "papermill": {
     "duration": 0.137418,
     "end_time": "2025-01-18T15:26:37.471238",
     "exception": false,
     "start_time": "2025-01-18T15:26:37.333820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Preprocessed_tokens</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>[that, look, amazing]</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>[the, FDA, have, plenty, to, criticize, but, l...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
       "      <td>[desktop, link, ^^/r, HelperBot, ^^downvote, ^...</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "211222                                 That looks amazing   \n",
       "211223  The FDA has plenty to criticize. But like here...   \n",
       "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...   \n",
       "\n",
       "                                      Preprocessed_tokens     emotion  \n",
       "211222                              [that, look, amazing]  admiration  \n",
       "211223  [the, FDA, have, plenty, to, criticize, but, l...       anger  \n",
       "211224  [desktop, link, ^^/r, HelperBot, ^^downvote, ^...  admiration  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df_mod.columns.tolist()\n",
    "last_col = cols[-1]\n",
    "cols.remove(last_col)\n",
    "cols.insert(1, last_col)\n",
    "df_mod= df_mod[cols]\n",
    "\n",
    "emotion_columns = df_mod.columns[-28:]\n",
    "df_mod['emotion'] = df_mod[emotion_columns].idxmax(axis=1)\n",
    "df_mod = df_mod.drop(columns=emotion_columns)\n",
    "\n",
    "df_mod.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b6cb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:26:37.487009Z",
     "iopub.status.busy": "2025-01-18T15:26:37.486769Z",
     "iopub.status.idle": "2025-01-18T15:26:38.842308Z",
     "shell.execute_reply": "2025-01-18T15:26:38.841519Z"
    },
    "papermill": {
     "duration": 1.365224,
     "end_time": "2025-01-18T15:26:38.844070",
     "exception": false,
     "start_time": "2025-01-18T15:26:37.478846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mod.to_csv('p_data.csv', index = False)\n",
    "df_suicide_mod.to_csv('p_suicide_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e944dec",
   "metadata": {
    "papermill": {
     "duration": 0.007965,
     "end_time": "2025-01-18T15:26:38.860711",
     "exception": false,
     "start_time": "2025-01-18T15:26:38.852746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Start Running program from here for all purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8618b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:26:38.877937Z",
     "iopub.status.busy": "2025-01-18T15:26:38.877649Z",
     "iopub.status.idle": "2025-01-18T15:28:45.658696Z",
     "shell.execute_reply": "2025-01-18T15:28:45.657634Z"
    },
    "papermill": {
     "duration": 126.798836,
     "end_time": "2025-01-18T15:28:45.667695",
     "exception": false,
     "start_time": "2025-01-18T15:26:38.868859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "neutral           55298\n",
      "admiration        20542\n",
      "approval          15530\n",
      "annoyance         11929\n",
      "disapproval        8917\n",
      "amusement          8862\n",
      "gratitude          8437\n",
      "anger              7956\n",
      "curiosity          7707\n",
      "disappointment     6769\n",
      "confusion          6600\n",
      "love               5310\n",
      "caring             5147\n",
      "realization        5125\n",
      "joy                5120\n",
      "optimism           4994\n",
      "excitement         4375\n",
      "sadness            3863\n",
      "surprise           3472\n",
      "disgust            3420\n",
      "desire             3002\n",
      "fear               2514\n",
      "embarrassment      1720\n",
      "remorse            1648\n",
      "nervousness         946\n",
      "relief              814\n",
      "pride               714\n",
      "grief               494\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "df_mod = pd.read_csv(\"/kaggle/input/preprocessed-data/p_data_full_stop.csv\")\n",
    "df_suicide_mod = pd.read_csv(\"/kaggle/input/preprocessed-data/p_suicide_data_30k_stop.csv\")\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('/kaggle/input/mental-wellbeing-chatbot/scikitlearn/default/2/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# def vectorize(tokens):\n",
    "#     vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "#     if vectors:\n",
    "#         return sum(vectors) / len(vectors)  \n",
    "#     else:\n",
    "#         return [0] * model.vector_size  \n",
    "\n",
    "def vectorize(tokens, model):\n",
    "    word_vectors = []\n",
    "    for word in tokens:\n",
    "        if word in model:\n",
    "            word_vector = model[word]  \n",
    "            word_vectors.append(word_vector)\n",
    "    if word_vectors:\n",
    "        sentence_vector = np.mean(word_vectors, axis=0)\n",
    "        return sentence_vector\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "df_mod['vector'] = df_mod['Preprocessed_tokens'].apply(lambda x: vectorize(x, model))\n",
    "df_suicide_mod['vector'] = df_suicide_mod['Preprocessed_tokens'].apply(lambda x: vectorize(x, model))\n",
    "\n",
    "emotion_counts = df_mod['emotion'].value_counts()\n",
    "print(emotion_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb95a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:45.682889Z",
     "iopub.status.busy": "2025-01-18T15:28:45.682636Z",
     "iopub.status.idle": "2025-01-18T15:28:45.694259Z",
     "shell.execute_reply": "2025-01-18T15:28:45.693427Z"
    },
    "papermill": {
     "duration": 0.02053,
     "end_time": "2025-01-18T15:28:45.695556",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.675026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Preprocessed_tokens</th>\n",
       "      <th>emotion</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>['that', 'game', 'hurt']</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.27539062, 0.17261353, -0.07705078, 0.10944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>[' ', '&gt;', 'sexuality', 'should', 'not', 'be',...</td>\n",
       "      <td>admiration</td>\n",
       "      <td>[-0.19681089, 0.111585006, 0.002059098, 0.1409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>['you', 'do', 'right', 'if', 'you', 'do', 'not...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.19564383, 0.111964636, 0.013619559, 0.1303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>['man', 'I', 'love', 'reddit']</td>\n",
       "      <td>love</td>\n",
       "      <td>[-0.09999906, 0.12735455, 0.012986403, 0.13516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>['name', 'be', 'nowhere', 'near', 'they', 'he'...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.14364716, 0.12471887, -0.01883212, 0.14475...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                    That game hurt.   \n",
       "1   >sexuality shouldn’t be a grouping category I...   \n",
       "2     You do right, if you don't care then fuck 'em!   \n",
       "3                                 Man I love reddit.   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...   \n",
       "\n",
       "                                 Preprocessed_tokens     emotion  \\\n",
       "0                           ['that', 'game', 'hurt']     sadness   \n",
       "1  [' ', '>', 'sexuality', 'should', 'not', 'be',...  admiration   \n",
       "2  ['you', 'do', 'right', 'if', 'you', 'do', 'not...     neutral   \n",
       "3                     ['man', 'I', 'love', 'reddit']        love   \n",
       "4  ['name', 'be', 'nowhere', 'near', 'they', 'he'...     neutral   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.27539062, 0.17261353, -0.07705078, 0.10944...  \n",
       "1  [-0.19681089, 0.111585006, 0.002059098, 0.1409...  \n",
       "2  [-0.19564383, 0.111964636, 0.013619559, 0.1303...  \n",
       "3  [-0.09999906, 0.12735455, 0.012986403, 0.13516...  \n",
       "4  [-0.14364716, 0.12471887, -0.01883212, 0.14475...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcd5b5",
   "metadata": {
    "papermill": {
     "duration": 0.006842,
     "end_time": "2025-01-18T15:28:45.709467",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.702625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Positive Sentiments:\n",
    "\n",
    "- Admiration: \"admiration\", \"approval\", \"pride\"\n",
    "Amusement: \"amusement\", \"excitement\", \"joy\"\n",
    "Love: \"love\", \"caring\", \"gratitude\"\n",
    "Optimism: \"optimism\", \"relief\"\n",
    "Neutral Sentiments:\n",
    "\n",
    "- Neutral: \"neutral\", \"realization\", \"curiosity\"\n",
    "Negative Sentiments:\n",
    "\n",
    "- Sadness: \"sadness\", \"grief\", \"remorse\", \"disappointment\"\n",
    "Anger: \"anger\", \"annoyance\", \"disapproval\"\n",
    "Fear: \"fear\", \"nervousness\", \"confusion\"\n",
    "Disgust: \"disgust\", \"embarrassment\"\n",
    "Surprise: \"surprise\", \"desire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db14565a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:45.724552Z",
     "iopub.status.busy": "2025-01-18T15:28:45.724282Z",
     "iopub.status.idle": "2025-01-18T15:28:45.754575Z",
     "shell.execute_reply": "2025-01-18T15:28:45.753729Z"
    },
    "papermill": {
     "duration": 0.039408,
     "end_time": "2025-01-18T15:28:45.755842",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.716434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 211225\n",
      "Filtered dataset size: 99760\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Preprocessed_tokens</th>\n",
       "      <th>emotion</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>['that', 'game', 'hurt']</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.27539062, 0.17261353, -0.07705078, 0.10944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>[' ', '&gt;', 'sexuality', 'should', 'not', 'be',...</td>\n",
       "      <td>admiration</td>\n",
       "      <td>[-0.19681089, 0.111585006, 0.002059098, 0.1409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>['man', 'I', 'love', 'reddit']</td>\n",
       "      <td>love</td>\n",
       "      <td>[-0.09999906, 0.12735455, 0.012986403, 0.13516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>That's crazy; I went to a super [RELIGION] hig...</td>\n",
       "      <td>['that', 'be', 'crazy', 'I', 'go', 'to', 'a', ...</td>\n",
       "      <td>amusement</td>\n",
       "      <td>[-0.17494032, 0.11104363, -0.0142862955, 0.144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that's adorable asf</td>\n",
       "      <td>['that', 'be', 'adorable', 'asf']</td>\n",
       "      <td>amusement</td>\n",
       "      <td>[-0.19988544, 0.16729267, -0.016310472, 0.1263...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                    That game hurt.   \n",
       "1   >sexuality shouldn’t be a grouping category I...   \n",
       "3                                 Man I love reddit.   \n",
       "7  That's crazy; I went to a super [RELIGION] hig...   \n",
       "8                                that's adorable asf   \n",
       "\n",
       "                                 Preprocessed_tokens     emotion  \\\n",
       "0                           ['that', 'game', 'hurt']     sadness   \n",
       "1  [' ', '>', 'sexuality', 'should', 'not', 'be',...  admiration   \n",
       "3                     ['man', 'I', 'love', 'reddit']        love   \n",
       "7  ['that', 'be', 'crazy', 'I', 'go', 'to', 'a', ...   amusement   \n",
       "8                  ['that', 'be', 'adorable', 'asf']   amusement   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.27539062, 0.17261353, -0.07705078, 0.10944...  \n",
       "1  [-0.19681089, 0.111585006, 0.002059098, 0.1409...  \n",
       "3  [-0.09999906, 0.12735455, 0.012986403, 0.13516...  \n",
       "7  [-0.17494032, 0.11104363, -0.0142862955, 0.144...  \n",
       "8  [-0.19988544, 0.16729267, -0.016310472, 0.1263...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the main emotions to keep\n",
    "main_emotions = [\"admiration\", \"amusement\", \"excitement\", \"anger\", \"fear\", \"joy\", \"confusion\", \"realization\", \"curiosity\"\n",
    "                 , \"love\", \"sadness\", \"grief\", \"remorse\", \"disappointment\" ,\"annoyance\", \"nervousness\"]\n",
    "\n",
    "print(f\"Original dataset size: {df_mod.shape[0]}\")\n",
    "\n",
    "df_mod = df_mod[df_mod['emotion'].isin(main_emotions)]\n",
    "\n",
    "print(f\"Filtered dataset size: {df_mod.shape[0]}\")\n",
    "\n",
    "df_mod.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87d17344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:45.771465Z",
     "iopub.status.busy": "2025-01-18T15:28:45.771225Z",
     "iopub.status.idle": "2025-01-18T15:28:45.886325Z",
     "shell.execute_reply": "2025-01-18T15:28:45.885340Z"
    },
    "papermill": {
     "duration": 0.124649,
     "end_time": "2025-01-18T15:28:45.887883",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.763234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries for each emotion:\n",
      "emotion\n",
      "happiness       38899\n",
      "anger           19885\n",
      "neutral         19432\n",
      "sadness         12774\n",
      "love             5310\n",
      "fear/anxiety     3460\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emotion_mapping = {\n",
    "    \"admiration\": \"happiness\",  \n",
    "    \"amusement\": \"happiness\", \n",
    "    \"excitement\": \"happiness\",\n",
    "    \"joy\": \"happiness\",\n",
    "    \"love\": \"love\",\n",
    "   # \"caring\": \"love\",\n",
    "    #\"optimism\": \"happiness\", # opt\n",
    "    \"curiosity\": \"neutral\",\n",
    "    #\"neutral\" : \"neutral\",\n",
    "    \"realization\": \"neutral\",\n",
    "    \"sadness\": \"sadness\",\n",
    "    \"grief\": \"sadness\",\n",
    "    \"remorse\": \"sadness\",\n",
    "    \"disappointment\": \"sadness\", \n",
    "    \"anger\": \"anger\",\n",
    "    \"annoyance\": \"anger\",\n",
    "    \"fear\": \"fear/anxiety\",\n",
    "    \"nervousness\": \"fear/anxiety\", # opt\n",
    "   # \"disgust\": \"disgust\",\n",
    "    \"confusion\": \"neutral\",\n",
    "   # \"surprise\": \"surprise\",# opt\n",
    "}\n",
    "\n",
    "df_mod['emotion'] = df_mod['emotion'].replace(emotion_mapping)\n",
    "\n",
    "emotion_to_int = {\n",
    "  # \"admiration\": 0, \n",
    "    \"happiness\": 1,\n",
    "    \"love\": 2,\n",
    "   # \"optimism\": 3,\n",
    "    \"neutral\": 3,\n",
    "    \"sadness\": 4,\n",
    "    \"anger\": 5,\n",
    "    \"fear/anxiety\": 6,\n",
    "   # \"surprise\": 8\n",
    "    \n",
    "}\n",
    "\n",
    "df_mod['emotion_int'] = df_mod['emotion'].map(emotion_to_int)\n",
    "\n",
    "df_suicide_mod['class_int'] = df_suicide_mod['class'].replace({'suicide': 1, 'non-suicide': 0})\n",
    "\n",
    "\n",
    "\n",
    "emotion_counts = df_mod['emotion'].value_counts()\n",
    "\n",
    "print(\"Number of entries for each emotion:\")\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61076db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:45.904070Z",
     "iopub.status.busy": "2025-01-18T15:28:45.903796Z",
     "iopub.status.idle": "2025-01-18T15:28:45.906814Z",
     "shell.execute_reply": "2025-01-18T15:28:45.906033Z"
    },
    "papermill": {
     "duration": 0.012077,
     "end_time": "2025-01-18T15:28:45.907949",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.895872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_mod.to_csv('p_v_data.csv', index = False)\n",
    "# df_suicide_mod.to_csv('p_v_suicide_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a537e778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:45.923286Z",
     "iopub.status.busy": "2025-01-18T15:28:45.923012Z",
     "iopub.status.idle": "2025-01-18T15:28:45.953813Z",
     "shell.execute_reply": "2025-01-18T15:28:45.953022Z"
    },
    "papermill": {
     "duration": 0.039919,
     "end_time": "2025-01-18T15:28:45.955164",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.915245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Preprocessed_tokens</th>\n",
       "      <th>emotion</th>\n",
       "      <th>vector</th>\n",
       "      <th>emotion_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>['that', 'game', 'hurt']</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.27539062, 0.17261353, -0.07705078, 0.10944...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>[' ', '&gt;', 'sexuality', 'should', 'not', 'be',...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.19681089, 0.111585006, 0.002059098, 0.1409...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>['man', 'I', 'love', 'reddit']</td>\n",
       "      <td>love</td>\n",
       "      <td>[-0.09999906, 0.12735455, 0.012986403, 0.13516...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>That's crazy; I went to a super [RELIGION] hig...</td>\n",
       "      <td>['that', 'be', 'crazy', 'I', 'go', 'to', 'a', ...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.17494032, 0.11104363, -0.0142862955, 0.144...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that's adorable asf</td>\n",
       "      <td>['that', 'be', 'adorable', 'asf']</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.19988544, 0.16729267, -0.016310472, 0.1263...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Sponge Blurb Pubs Quaw Haha GURR ha AAa!\" fin...</td>\n",
       "      <td>['Sponge', 'Blurb', 'Pubs', 'Quaw', 'Haha', 'G...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.15698548, 0.111558534, 0.03517456, 0.09603...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I wanted to downvote this, but it's not your f...</td>\n",
       "      <td>['I', 'want', 'to', 'downvote', 'this', 'but',...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.18965112, 0.11191391, -0.034405965, 0.1326...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>That is odd.</td>\n",
       "      <td>['that', 'be', 'odd']</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.19763184, 0.18621826, -0.043380737, 0.1411...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I appreciate it, that's good to know. I hope I...</td>\n",
       "      <td>['I', 'appreciate', 'it', 'that', 'be', 'good'...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.14584547, 0.11323252, -0.032575052, 0.1617...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Well then I’d say you have a pretty good chanc...</td>\n",
       "      <td>['well', 'then', 'I', '’d', 'say', 'you', 'hav...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.15911202, 0.11998915, -0.0011517069, 0.124...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pretty much every Punjabi dude I've met.</td>\n",
       "      <td>['pretty', 'much', 'every', 'Punjabi', 'dude',...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.14696711, 0.12535419, 0.019544197, 0.13668...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>For extra measure tape it right by your crotch...</td>\n",
       "      <td>['for', 'extra', 'measure', 'tape', 'it', 'rig...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[-0.20946458, 0.124801636, -0.0118731335, 0.12...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What does Clemson give pride stickers for? Sna...</td>\n",
       "      <td>['what', 'do', 'Clemson', 'give', 'pride', 'st...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.15525417, 0.10982955, 0.0058722245, 0.1546...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Now I'm wondering on what I've been missing ou...</td>\n",
       "      <td>['now', 'I', 'be', 'wonder', 'on', 'what', 'I'...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.17445795, 0.09819128, -0.0063476562, 0.144...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Seeeee! We have one of them coloureds too!\"</td>\n",
       "      <td>['seeeee', 'we', 'have', 'one', 'of', 'they', ...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.14565548, 0.13530116, -0.007981824, 0.1259...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lots, play store or apple store vpn. Nord is good</td>\n",
       "      <td>['lot', 'play', 'store', 'or', 'apple', 'store...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.15100098, 0.1360648, -0.0126778735, 0.1440...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dark and funny, but not really nice guy. He ha...</td>\n",
       "      <td>['Dark', 'and', 'funny', 'but', 'not', 'really...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.1631941, 0.12777516, -0.008989938, 0.12601...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nice!! I'll try this one</td>\n",
       "      <td>['nice', 'I', 'will', 'try', 'this', 'one']</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.16287392, 0.102428235, -0.032714844, 0.142...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I just came home, what the fuck is this lineup...</td>\n",
       "      <td>['I', 'just', 'come', 'home', 'what', 'the', '...</td>\n",
       "      <td>love</td>\n",
       "      <td>[-0.16828482, 0.11915044, 0.0052740914, 0.1303...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Go troll elsewhere. This woman needs support, ...</td>\n",
       "      <td>['go', 'troll', 'elsewhere', 'this', 'woman', ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[-0.18614013, 0.13084595, -0.035661623, 0.1325...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Just rumors online, it most likely won't happen</td>\n",
       "      <td>['just', 'rumor', 'online', 'it', 'most', 'lik...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[-0.16226901, 0.10929362, -0.031167055, 0.1345...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Na. Rediting my post. Sorry for the ignorance.</td>\n",
       "      <td>['na', 'redite', 'my', 'post', 'sorry', 'for',...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.19248772, 0.12007713, -0.011615753, 0.1505...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Because the content creators don't deserve to ...</td>\n",
       "      <td>['because', 'the', 'content', 'creator', 'do',...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.15822266, 0.12513347, -0.012109375, 0.1379...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pity. I had some decent lunches there, but nev...</td>\n",
       "      <td>['pity', 'I', 'have', 'some', 'decent', 'lunch...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[-0.17273447, 0.12682296, -0.021260165, 0.1370...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>By far the coolest thing I've seen on this thr...</td>\n",
       "      <td>['by', 'far', 'the', 'cool', 'thing', 'I', 'ha...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.18429318, 0.13780831, -0.012154244, 0.1310...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>&gt;not a cure-all. Since we don't have such a th...</td>\n",
       "      <td>['&gt;', 'not', 'a', 'cure', 'all', 'since', 'we'...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.18941142, 0.1100647, -0.025465902, 0.13325...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Oh whoops, I misread the original comment</td>\n",
       "      <td>['oh', 'whoop', 'I', 'misread', 'the', 'origin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.17899446, 0.122130364, -0.024154171, 0.145...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sending love and strength vibes &lt;3</td>\n",
       "      <td>['send', 'love', 'and', 'strength', 'vibe', '&lt;3']</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.12662672, 0.111707605, 0.013178286, 0.1311...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>She’s like a kewpie doll with them. Precious.</td>\n",
       "      <td>['she', '’', 'like', 'a', 'kewpie', 'doll', 'w...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.16109212, 0.119185016, -0.015347567, 0.152...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Not knowing what it is, for one thing.</td>\n",
       "      <td>['not', 'know', 'what', 'it', 'be', 'for', 'on...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.19052735, 0.08702393, -0.04885742, 0.16046...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0                                     That game hurt.   \n",
       "1    >sexuality shouldn’t be a grouping category I...   \n",
       "3                                  Man I love reddit.   \n",
       "7   That's crazy; I went to a super [RELIGION] hig...   \n",
       "8                                 that's adorable asf   \n",
       "9   \"Sponge Blurb Pubs Quaw Haha GURR ha AAa!\" fin...   \n",
       "11  I wanted to downvote this, but it's not your f...   \n",
       "13                                       That is odd.   \n",
       "15  I appreciate it, that's good to know. I hope I...   \n",
       "17  Well then I’d say you have a pretty good chanc...   \n",
       "18           Pretty much every Punjabi dude I've met.   \n",
       "19  For extra measure tape it right by your crotch...   \n",
       "21  What does Clemson give pride stickers for? Sna...   \n",
       "23  Now I'm wondering on what I've been missing ou...   \n",
       "25       \"Seeeee! We have one of them coloureds too!\"   \n",
       "28  Lots, play store or apple store vpn. Nord is good   \n",
       "32  Dark and funny, but not really nice guy. He ha...   \n",
       "35                           nice!! I'll try this one   \n",
       "37  I just came home, what the fuck is this lineup...   \n",
       "38  Go troll elsewhere. This woman needs support, ...   \n",
       "39    Just rumors online, it most likely won't happen   \n",
       "40     Na. Rediting my post. Sorry for the ignorance.   \n",
       "41  Because the content creators don't deserve to ...   \n",
       "42  Pity. I had some decent lunches there, but nev...   \n",
       "43  By far the coolest thing I've seen on this thr...   \n",
       "45  >not a cure-all. Since we don't have such a th...   \n",
       "48          Oh whoops, I misread the original comment   \n",
       "49                 Sending love and strength vibes <3   \n",
       "50      She’s like a kewpie doll with them. Precious.   \n",
       "51             Not knowing what it is, for one thing.   \n",
       "\n",
       "                                  Preprocessed_tokens    emotion  \\\n",
       "0                            ['that', 'game', 'hurt']    sadness   \n",
       "1   [' ', '>', 'sexuality', 'should', 'not', 'be',...  happiness   \n",
       "3                      ['man', 'I', 'love', 'reddit']       love   \n",
       "7   ['that', 'be', 'crazy', 'I', 'go', 'to', 'a', ...  happiness   \n",
       "8                   ['that', 'be', 'adorable', 'asf']  happiness   \n",
       "9   ['Sponge', 'Blurb', 'Pubs', 'Quaw', 'Haha', 'G...  happiness   \n",
       "11  ['I', 'want', 'to', 'downvote', 'this', 'but',...    sadness   \n",
       "13                              ['that', 'be', 'odd']    sadness   \n",
       "15  ['I', 'appreciate', 'it', 'that', 'be', 'good'...  happiness   \n",
       "17  ['well', 'then', 'I', '’d', 'say', 'you', 'hav...    neutral   \n",
       "18  ['pretty', 'much', 'every', 'Punjabi', 'dude',...  happiness   \n",
       "19  ['for', 'extra', 'measure', 'tape', 'it', 'rig...      anger   \n",
       "21  ['what', 'do', 'Clemson', 'give', 'pride', 'st...    neutral   \n",
       "23  ['now', 'I', 'be', 'wonder', 'on', 'what', 'I'...    neutral   \n",
       "25  ['seeeee', 'we', 'have', 'one', 'of', 'they', ...  happiness   \n",
       "28  ['lot', 'play', 'store', 'or', 'apple', 'store...  happiness   \n",
       "32  ['Dark', 'and', 'funny', 'but', 'not', 'really...    sadness   \n",
       "35        ['nice', 'I', 'will', 'try', 'this', 'one']  happiness   \n",
       "37  ['I', 'just', 'come', 'home', 'what', 'the', '...       love   \n",
       "38  ['go', 'troll', 'elsewhere', 'this', 'woman', ...      anger   \n",
       "39  ['just', 'rumor', 'online', 'it', 'most', 'lik...      anger   \n",
       "40  ['na', 'redite', 'my', 'post', 'sorry', 'for',...    sadness   \n",
       "41  ['because', 'the', 'content', 'creator', 'do',...    neutral   \n",
       "42  ['pity', 'I', 'have', 'some', 'decent', 'lunch...    sadness   \n",
       "43  ['by', 'far', 'the', 'cool', 'thing', 'I', 'ha...  happiness   \n",
       "45  ['>', 'not', 'a', 'cure', 'all', 'since', 'we'...    neutral   \n",
       "48  ['oh', 'whoop', 'I', 'misread', 'the', 'origin...    neutral   \n",
       "49  ['send', 'love', 'and', 'strength', 'vibe', '<3']  happiness   \n",
       "50  ['she', '’', 'like', 'a', 'kewpie', 'doll', 'w...  happiness   \n",
       "51  ['not', 'know', 'what', 'it', 'be', 'for', 'on...    neutral   \n",
       "\n",
       "                                               vector  emotion_int  \n",
       "0   [-0.27539062, 0.17261353, -0.07705078, 0.10944...            4  \n",
       "1   [-0.19681089, 0.111585006, 0.002059098, 0.1409...            1  \n",
       "3   [-0.09999906, 0.12735455, 0.012986403, 0.13516...            2  \n",
       "7   [-0.17494032, 0.11104363, -0.0142862955, 0.144...            1  \n",
       "8   [-0.19988544, 0.16729267, -0.016310472, 0.1263...            1  \n",
       "9   [-0.15698548, 0.111558534, 0.03517456, 0.09603...            1  \n",
       "11  [-0.18965112, 0.11191391, -0.034405965, 0.1326...            4  \n",
       "13  [-0.19763184, 0.18621826, -0.043380737, 0.1411...            4  \n",
       "15  [-0.14584547, 0.11323252, -0.032575052, 0.1617...            1  \n",
       "17  [-0.15911202, 0.11998915, -0.0011517069, 0.124...            3  \n",
       "18  [-0.14696711, 0.12535419, 0.019544197, 0.13668...            1  \n",
       "19  [-0.20946458, 0.124801636, -0.0118731335, 0.12...            5  \n",
       "21  [-0.15525417, 0.10982955, 0.0058722245, 0.1546...            3  \n",
       "23  [-0.17445795, 0.09819128, -0.0063476562, 0.144...            3  \n",
       "25  [-0.14565548, 0.13530116, -0.007981824, 0.1259...            1  \n",
       "28  [-0.15100098, 0.1360648, -0.0126778735, 0.1440...            1  \n",
       "32  [-0.1631941, 0.12777516, -0.008989938, 0.12601...            4  \n",
       "35  [-0.16287392, 0.102428235, -0.032714844, 0.142...            1  \n",
       "37  [-0.16828482, 0.11915044, 0.0052740914, 0.1303...            2  \n",
       "38  [-0.18614013, 0.13084595, -0.035661623, 0.1325...            5  \n",
       "39  [-0.16226901, 0.10929362, -0.031167055, 0.1345...            5  \n",
       "40  [-0.19248772, 0.12007713, -0.011615753, 0.1505...            4  \n",
       "41  [-0.15822266, 0.12513347, -0.012109375, 0.1379...            3  \n",
       "42  [-0.17273447, 0.12682296, -0.021260165, 0.1370...            4  \n",
       "43  [-0.18429318, 0.13780831, -0.012154244, 0.1310...            1  \n",
       "45  [-0.18941142, 0.1100647, -0.025465902, 0.13325...            3  \n",
       "48  [-0.17899446, 0.122130364, -0.024154171, 0.145...            3  \n",
       "49  [-0.12662672, 0.111707605, 0.013178286, 0.1311...            1  \n",
       "50  [-0.16109212, 0.119185016, -0.015347567, 0.152...            1  \n",
       "51  [-0.19052735, 0.08702393, -0.04885742, 0.16046...            3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835bc74",
   "metadata": {
    "papermill": {
     "duration": 0.007767,
     "end_time": "2025-01-18T15:28:45.970974",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.963207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st Checkpoint \n",
    "Data has been preprocessed and vectorised, and emotions have been converted into labels to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4609da1",
   "metadata": {
    "papermill": {
     "duration": 0.007822,
     "end_time": "2025-01-18T15:28:45.986821",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.978999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training - Emotion Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7614ba48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:46.003125Z",
     "iopub.status.busy": "2025-01-18T15:28:46.002866Z",
     "iopub.status.idle": "2025-01-18T15:28:46.238605Z",
     "shell.execute_reply": "2025-01-18T15:28:46.237682Z"
    },
    "papermill": {
     "duration": 0.245547,
     "end_time": "2025-01-18T15:28:46.239950",
     "exception": false,
     "start_time": "2025-01-18T15:28:45.994403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99760, 300) (79808, 300) (19952, 300)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = np.array(df_mod['vector'].tolist())\n",
    "Y = df_mod['emotion_int'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=42)\n",
    "\n",
    "print(X.shape, X_train.shape, X_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b62bd",
   "metadata": {
    "papermill": {
     "duration": 0.007978,
     "end_time": "2025-01-18T15:28:46.256194",
     "exception": false,
     "start_time": "2025-01-18T15:28:46.248216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">Training the Machine Learning Model (Using logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a82e38f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:46.272941Z",
     "iopub.status.busy": "2025-01-18T15:28:46.272693Z",
     "iopub.status.idle": "2025-01-18T15:28:46.544720Z",
     "shell.execute_reply": "2025-01-18T15:28:46.543991Z"
    },
    "papermill": {
     "duration": 0.282184,
     "end_time": "2025-01-18T15:28:46.546291",
     "exception": false,
     "start_time": "2025-01-18T15:28:46.264107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15ac2e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:28:46.563721Z",
     "iopub.status.busy": "2025-01-18T15:28:46.563422Z",
     "iopub.status.idle": "2025-01-18T15:29:50.613656Z",
     "shell.execute_reply": "2025-01-18T15:29:50.612454Z"
    },
    "papermill": {
     "duration": 64.060276,
     "end_time": "2025-01-18T15:29:50.615054",
     "exception": false,
     "start_time": "2025-01-18T15:28:46.554778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy:  0.5926222935044105\n",
      "Training data accuracy:  0.841018444266239\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "model1.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model1.predict(X_test)\n",
    "print(\"Test data accuracy: \", accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "Y_pred2 = model1.predict(X_train)\n",
    "print(\"Training data accuracy: \", accuracy_score(Y_train, Y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0617dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:29:50.632191Z",
     "iopub.status.busy": "2025-01-18T15:29:50.631939Z",
     "iopub.status.idle": "2025-01-18T15:36:38.057768Z",
     "shell.execute_reply": "2025-01-18T15:36:38.055431Z"
    },
    "papermill": {
     "duration": 407.460618,
     "end_time": "2025-01-18T15:36:38.083916",
     "exception": false,
     "start_time": "2025-01-18T15:29:50.623298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8405798917401764\n",
      "Testing Accuracy:  0.6139234161988774\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.82      0.73      7780\n",
      "           2       0.66      0.38      0.49      1062\n",
      "           3       0.59      0.54      0.56      3886\n",
      "           4       0.55      0.41      0.47      2555\n",
      "           5       0.57      0.52      0.54      3977\n",
      "           6       0.59      0.33      0.42       692\n",
      "\n",
      "    accuracy                           0.61     19952\n",
      "   macro avg       0.60      0.50      0.53     19952\n",
      "weighted avg       0.61      0.61      0.60     19952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('lr', LogisticRegression(max_iter=500, random_state=42, n_jobs=-1)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1))\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=500, random_state=42)\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=3, n_jobs=-1)\n",
    "\n",
    "stacking_clf.fit(X_train, Y_train)\n",
    "\n",
    "y_train_pred = stacking_clf.predict(X_train)\n",
    "y_test_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(Y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(Y_test, y_test_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", train_accuracy)\n",
    "print(\"Testing Accuracy: \", test_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8b53b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.119649Z",
     "iopub.status.busy": "2025-01-18T15:36:38.119318Z",
     "iopub.status.idle": "2025-01-18T15:36:38.394004Z",
     "shell.execute_reply": "2025-01-18T15:36:38.392908Z"
    },
    "papermill": {
     "duration": 0.285856,
     "end_time": "2025-01-18T15:36:38.395823",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.109967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"emotion_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(stacking_clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc982c5",
   "metadata": {
    "papermill": {
     "duration": 0.009112,
     "end_time": "2025-01-18T15:36:38.414929",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.405817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ee617",
   "metadata": {
    "papermill": {
     "duration": 0.008982,
     "end_time": "2025-01-18T15:36:38.433394",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.424412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1caac777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.451144Z",
     "iopub.status.busy": "2025-01-18T15:36:38.450829Z",
     "iopub.status.idle": "2025-01-18T15:36:38.465336Z",
     "shell.execute_reply": "2025-01-18T15:36:38.464560Z"
    },
    "papermill": {
     "duration": 0.024609,
     "end_time": "2025-01-18T15:36:38.466702",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.442093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'be', 'happy', 'and', 'adorable']\n"
     ]
    }
   ],
   "source": [
    "sentence3 = \"i am happy and adorable\"\n",
    "\n",
    "word_tokens3 = preprocess_tokens(sentence3)\n",
    "print(word_tokens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0206d97f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.483387Z",
     "iopub.status.busy": "2025-01-18T15:36:38.483163Z",
     "iopub.status.idle": "2025-01-18T15:36:38.488244Z",
     "shell.execute_reply": "2025-01-18T15:36:38.487554Z"
    },
    "papermill": {
     "duration": 0.014653,
     "end_time": "2025-01-18T15:36:38.489317",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.474664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_tokens3 = vectorize(word_tokens3, model)\n",
    "vector_tokens3 = np.array(vector_tokens3)\n",
    "vector_tokens3 = np.reshape(vector_tokens3, (1, -1))\n",
    "vector_tokens3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a5dd7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.506545Z",
     "iopub.status.busy": "2025-01-18T15:36:38.506242Z",
     "iopub.status.idle": "2025-01-18T15:36:38.535702Z",
     "shell.execute_reply": "2025-01-18T15:36:38.534816Z"
    },
    "papermill": {
     "duration": 0.039643,
     "end_time": "2025-01-18T15:36:38.537028",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.497385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3 = model1.predict(vector_tokens3)\n",
    "Y3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a30bee36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.554997Z",
     "iopub.status.busy": "2025-01-18T15:36:38.554759Z",
     "iopub.status.idle": "2025-01-18T15:36:38.569376Z",
     "shell.execute_reply": "2025-01-18T15:36:38.568364Z"
    },
    "papermill": {
     "duration": 0.024722,
     "end_time": "2025-01-18T15:36:38.570606",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.545884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 31119, 5: 15908, 3: 15546, 4: 10219, 2: 4248, 6: 2768})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(Y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3de7d1",
   "metadata": {
    "papermill": {
     "duration": 0.00791,
     "end_time": "2025-01-18T15:36:38.586741",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.578831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Suicide detection classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cfd2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T15:07:25.608717Z",
     "iopub.status.busy": "2025-01-10T15:07:25.608315Z",
     "iopub.status.idle": "2025-01-10T15:07:25.616097Z",
     "shell.execute_reply": "2025-01-10T15:07:25.614533Z",
     "shell.execute_reply.started": "2025-01-10T15:07:25.608688Z"
    },
    "papermill": {
     "duration": 0.008287,
     "end_time": "2025-01-18T15:36:38.603276",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.594989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">using json module to convert the strings to a list of floats,\n",
    "as the ast.literal_eval method was giving error, as it comes out some of the entries\n",
    "were already of list type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e7101b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.620527Z",
     "iopub.status.busy": "2025-01-18T15:36:38.620254Z",
     "iopub.status.idle": "2025-01-18T15:36:38.623212Z",
     "shell.execute_reply": "2025-01-18T15:36:38.622561Z"
    },
    "papermill": {
     "duration": 0.012958,
     "end_time": "2025-01-18T15:36:38.624410",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.611452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Fix the formatting by adding commas between numbers\n",
    "# df_suicide_mod['vector'] = df_suicide_mod['vector'].apply(\n",
    "#     lambda x: re.sub(r'(?<=\\d)\\s+(?=[\\-\\d])', ', ', x.strip())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "623b6dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.641554Z",
     "iopub.status.busy": "2025-01-18T15:36:38.641298Z",
     "iopub.status.idle": "2025-01-18T15:36:38.644464Z",
     "shell.execute_reply": "2025-01-18T15:36:38.643696Z"
    },
    "papermill": {
     "duration": 0.013256,
     "end_time": "2025-01-18T15:36:38.645844",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.632588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_suicide_mod['vector'] = df_suicide_mod['vector'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04f11158",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.663025Z",
     "iopub.status.busy": "2025-01-18T15:36:38.662783Z",
     "iopub.status.idle": "2025-01-18T15:36:38.696089Z",
     "shell.execute_reply": "2025-01-18T15:36:38.695420Z"
    },
    "papermill": {
     "duration": 0.043308,
     "end_time": "2025-01-18T15:36:38.697403",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.654095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = np.array(df_suicide_mod['vector'].tolist())\n",
    "B = df_suicide_mod['class_int'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a6cf5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.715123Z",
     "iopub.status.busy": "2025-01-18T15:36:38.714861Z",
     "iopub.status.idle": "2025-01-18T15:36:38.742271Z",
     "shell.execute_reply": "2025-01-18T15:36:38.741269Z"
    },
    "papermill": {
     "duration": 0.037431,
     "end_time": "2025-01-18T15:36:38.743498",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.706067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 300) (24000, 300) (6000, 300)\n"
     ]
    }
   ],
   "source": [
    "A_train, A_test, B_train, B_test = train_test_split(A, B, test_size=0.2, stratify = B, random_state=34)\n",
    "\n",
    "print(A.shape, A_train.shape, A_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb52b6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:36:38.761090Z",
     "iopub.status.busy": "2025-01-18T15:36:38.760827Z",
     "iopub.status.idle": "2025-01-18T15:37:01.019191Z",
     "shell.execute_reply": "2025-01-18T15:37:01.018186Z"
    },
    "papermill": {
     "duration": 22.268706,
     "end_time": "2025-01-18T15:37:01.020663",
     "exception": false,
     "start_time": "2025-01-18T15:36:38.751957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9999583333333333\n",
      "Test data accuracy:  0.8055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model2 = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model2.fit(A_train, B_train)\n",
    "\n",
    "B_pred2 = model2.predict(A_train)\n",
    "print(\"Training data accuracy: \", accuracy_score(B_train, B_pred2))\n",
    "\n",
    "B_pred = model2.predict(A_test)\n",
    "print(\"Test data accuracy: \", accuracy_score(B_test, B_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfbacd35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:37:01.038907Z",
     "iopub.status.busy": "2025-01-18T15:37:01.038658Z",
     "iopub.status.idle": "2025-01-18T15:37:01.076171Z",
     "shell.execute_reply": "2025-01-18T15:37:01.075394Z"
    },
    "papermill": {
     "duration": 0.048066,
     "end_time": "2025-01-18T15:37:01.077842",
     "exception": false,
     "start_time": "2025-01-18T15:37:01.029776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"suicide_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd4fcfbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:37:01.095800Z",
     "iopub.status.busy": "2025-01-18T15:37:01.095557Z",
     "iopub.status.idle": "2025-01-18T15:37:01.108409Z",
     "shell.execute_reply": "2025-01-18T15:37:01.107590Z"
    },
    "papermill": {
     "duration": 0.023056,
     "end_time": "2025-01-18T15:37:01.109722",
     "exception": false,
     "start_time": "2025-01-18T15:37:01.086666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'do', 'not', 'want', 'to', 'live', 'this', 'life', 'I', 'want', 'to', 'die']\n"
     ]
    }
   ],
   "source": [
    "sentence2 = \"I dont want to live this life, i want to die\"\n",
    "\n",
    "word_tokens2 = preprocess_tokens(sentence2)\n",
    "print(word_tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8019e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:37:01.127882Z",
     "iopub.status.busy": "2025-01-18T15:37:01.127660Z",
     "iopub.status.idle": "2025-01-18T15:37:01.132725Z",
     "shell.execute_reply": "2025-01-18T15:37:01.131912Z"
    },
    "papermill": {
     "duration": 0.015301,
     "end_time": "2025-01-18T15:37:01.133887",
     "exception": false,
     "start_time": "2025-01-18T15:37:01.118586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_tokens2 = vectorize(word_tokens2, model)\n",
    "vector_tokens2 = np.array(vector_tokens2)\n",
    "vector_tokens2 = np.reshape(vector_tokens2, (1, -1))\n",
    "vector_tokens2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "912bbcb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T15:37:01.151369Z",
     "iopub.status.busy": "2025-01-18T15:37:01.151142Z",
     "iopub.status.idle": "2025-01-18T15:37:01.179535Z",
     "shell.execute_reply": "2025-01-18T15:37:01.178759Z"
    },
    "papermill": {
     "duration": 0.038666,
     "end_time": "2025-01-18T15:37:01.180833",
     "exception": false,
     "start_time": "2025-01-18T15:37:01.142167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suicide Risk = High\n"
     ]
    }
   ],
   "source": [
    "Y2 = model2.predict(vector_tokens2)\n",
    "if Y2 == 1:\n",
    "    print(\"Suicide Risk = High\")\n",
    "else:\n",
    "    print(\"Suicide Risk = Low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c773b23",
   "metadata": {
    "papermill": {
     "duration": 0.008348,
     "end_time": "2025-01-18T15:37:01.198414",
     "exception": false,
     "start_time": "2025-01-18T15:37:01.190066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1995224,
     "datasetId": 1060121,
     "sourceId": 1956405,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10835588,
     "datasetId": 6484872,
     "sourceId": 10506492,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 2291570,
     "datasetId": 1075326,
     "sourceId": 2250642,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10833900,
     "modelInstanceId": 200229,
     "sourceId": 235123,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1886.60879,
   "end_time": "2025-01-18T15:37:04.067992",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-18T15:05:37.459202",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
